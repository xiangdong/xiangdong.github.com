---
layout: post
title: ARIA: Automatic Resource Inference and Allocation for MapReduce Environments 笔记
categories: [mapreduce, scheduling]
---
# {{page.title}}

[ARIA: Automatic Resource Inference and Allocation for MapReduce Environments](http://www.hpl.hp.com/techreports/2011/HPL-2011-58.html) 这是来自HP Lab的一篇论文。ARIA项目实际上产生了[一系列论文](http://www.hpl.hp.com/personal/Lucy_Cherkasova/projects/aria.html)。

按照[ARIA项目主页](http://www.hpl.hp.com/personal/Lucy_Cherkasova/projects/aria.html)的介绍，其工作主要分成三大块：

1. SLO-based scheduler for Hadoop
2. Right-Sizing of Resource Allocation for MapReduce Apps 
3. MapReduce Simulator SimMR 

[ARIA: Automatic Resource Inference and Allocation for MapReduce Environments](http://www.hpl.hp.com/techreports/2011/HPL-2011-58.html) 这篇论文出现在ICAC'2011，文章主要分成三部分：
1. MapReduce job profile。假设企业内部有job会定期的运行在新的数据集上，那么对于这些Job，作者identify了反应其Performance的关键特性，通过这些特性就有可能推算出job的completion time。
2. Performance model. 对于特定job，已知其job profile，input data size，给定soft deadline，计算出其需要的map/reduce task。
3. SLO-scheduler 根据1、2，实现SLO-scheduler。调度器的主要任务有两点： 对Job进行排序（依据EDF原则，Earliest Deadline Frist）; 以及依据performance model为相应job分配资源。

## Job profile

对于Map task来说，有5个关键数据。

对于reduce，task，作者区分了第一波shuffle（因为shuffle总是会等待所有的map跑完，但是如果reduce task也分成好几波该如何处理？）和其他的reduce task。


## performance model
给定input size，给定确定deadline，对于job来说，存在
a/m+b/r=D
其中a/b/D都是常数，可以根据job profile，input size，deadline算出来。m/r分别是需要的map/reduce的task的数量。
给定target函数 f(m,r)=m + r, 求极小值，可以计算出相应的m，r。 这就是scheduler的依据。

## scheduler
细节见paper。










 




